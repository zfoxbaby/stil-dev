"""Utility to convert STIL files to simple GASC format.

This script demonstrates how to use the ``STILParser`` from the project to
parse a STIL file and extract a very small subset of the information.  The
result is written to a ``.gasc`` file with a structure similar to the one
requested in the user instructions.

The script is intentionally lightweight and only relies on the parse tree
structure generated by ``STILParser``.  It walks the tree and collects:

* The signal names declared in the ``Signals`` block.
* The vector data contained in pattern statements.
* Micro-instructions (``Call``, ``Loop``, ``Stop`` â€¦) that immediately
  precede a vector.
* The active waveform table (``W`` statement).

The produced ``.gasc`` file contains a header with the list of signals and a
``SPM_PATTERN (SCAN)`` block with one line per vector.  Each line contains the
vector data, the micro-instruction and the waveform table name, when
available.

Note
----
The repository does not ship the ``lark`` dependency that powers the parser.
Running this script requires installing ``lark`` into the environment.
"""

from __future__ import annotations

import os
import sys
from dataclasses import dataclass
from typing import List

from lark import Tree, Token

try:  # Try importing the package as an installed dependency first
    from Semi_ATE.STIL.parsers.STILParser import STILParser
except ImportError:  # pragma: no cover - fallback for local execution
    repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, repo_root)
    from Semi_ATE.STIL.parsers.STILParser import STILParser

from lark import Tree, Token


@dataclass
class PatternLine:
    vec: str
    instr: str
    wft: str

class STILToGasc():
    """Convert STIL files to a simple GASC-like format - OPTIMIZED VERSION."""

    def __init__(self, stil_file, target_file, fast_mode=True):
        """Initialize converter.
        
        Args:
            stil_file: Path to input STIL file
            target_file: Path to output GASC file  
            fast_mode: If True, use optimizations for better performance on large files
        """
        self.stil_file = stil_file
        self.target_file = target_file
        self.fast_mode = fast_mode
        
        # Pattern line tracking
        self.current_wft = ""
        self.wft_pending = False
        self.pat_header: List[str] = []
        self.need_append_header = True

    def extract_signals(self, tree: Tree) -> List[str]:
        """Extract signal names from Signals block - OPTIMIZED."""
        signals: List[str] = []
        
        # Keep original node name that works
        for node in tree.find_data("b_signals__signals_list"):
            token = node.children[0]
            if isinstance(token, Token):
                signals.append(token.value.strip("\""))
        return signals

    def extract_signal_groups(self, tree: Tree) -> dict[str, List[str]]:
        """Extract signal groups mapping - keep original working logic."""
        groups: dict[str, List[str]] = {}
        
        # Keep original node name that works
        for node in tree.find_data("b_signal_groups__signal_groups_list"):
            tokens = [c for c in node.children if isinstance(c, Token)]
            if len(tokens) < 2:
                continue
            name = tokens[0].value
            sigs: List[str] = [tokens[1].value.strip("\"")]
            
            for vb in node.find_data("b_signal_groups__sigref_expr"):
                for n in vb.children:
                    if isinstance(n, Token) and n != "+":
                        sigs.append(n.value.strip("\""))
            
            groups[name] = sigs
        return groups

    def expand_vec_data(self, data: str) -> str:
        """Expand repeat directives like ``\r98 X`` inside vector data."""
        parts = data.split()
        result = ""
        i = 0
        while i < len(parts):
            part = parts[i]
            if part.startswith("\\r") and len(part) > 2:
                repeat = int(part[2:])
                result += parts[i + 1] * repeat
                i += 2
            else:
                result += part
                i += 1
        return result

    def emit(self, vec: str, instr: str, lines: List[PatternLine], current_wft: str, wft_pending: bool) -> None:
            wft = current_wft if wft_pending else ""
            if wft_pending:
                self.wft_pending = False
            lines.append(PatternLine(vec=vec, instr=instr, wft=wft))

    # get Tree under b_pattern__pattern_statements_
    def process(self, node: Tree, lines: List[PatternLine], signal_count: int ) -> None:
        if not isinstance(node, Tree):
            return
        data = node.data
        if data.endswith("pattern_statement"):
            for child in node.children:
                self.process(child, lines, signal_count)
            return
        # skip annotation, open_pattern_block, close_pattern_block
        if (data.endswith("annotation")
         or data.endswith("open_pattern_block")
         or data.endswith("close_pattern_block")):
            return
        # get waveform table name from w_stmt
        if data.endswith("w_stmt"):
            tokens = [t.value for t in node.children if isinstance(t, Token)]
            if len(tokens) >= 2:
                self.current_wft = tokens[1]
                self.wft_pending = True
            return
        # get micro-instruction from pattern_statement
        micro_tokens = [c.value for c in node.children if isinstance(c, Token)][:2]
        micro = " ".join(micro_tokens)
        if micro == "V":
            micro = ""
        # get vec_block Tree under b_pattern__pattern_statements_
        has_vec = any(isinstance(ch, Tree) and ch.data.endswith("vec_block") for ch in node.children)
        # get pattern_statement Tree under b_pattern__pattern_statements_
        nested = [ch for ch in node.children if isinstance(ch, Tree) and ch.data.endswith("pattern_statement")]
        # get vec_data_block Tree under b_pattern__pattern_statements_
        if has_vec:
            # record header when read first V list
            vec_parts: List[str] = []
            for vb in node.iter_subtrees():
                if isinstance(vb, Tree) and vb.data.endswith("vec_data_block"):
                    vec_tokens = [t.value for t in vb.scan_values(lambda c: isinstance(c, Token))]
                    if vec_tokens:
                        if self.need_append_header:
                            self.pat_header.append(vec_tokens[0].strip())
                        vec_parts.append(self.expand_vec_data(vec_tokens[-1].strip()))
            vec = "".join(vec_parts)
            self.need_append_header = False;
            self.emit(vec, micro, lines, self.current_wft, self.wft_pending)
            return
        if nested:
            start_idx = len(lines)
            for child in nested:
                self.process(child, lines, signal_count)
            end_idx = len(lines)
            if start_idx < end_idx:
                lines[start_idx].instr = micro
                #lines[end_idx - 1].instr = "RETURN"
            return

        vec = "X" * signal_count
        self.emit(vec, micro, lines, self.current_wft, self.wft_pending)

    def extract_pattern_lines(self, tree: Tree, signal_count: int) -> List[PatternLine]:
        """Extract pattern lines (vector + micro-instruction + waveform) - OPTIMIZED."""
        lines: List[PatternLine] = []
        
        # OPTIMIZATION: Use find_data instead of iter_subtrees for better performance
        pattern_blocks = tree.find_data("pattern_block")
        
        for block in pattern_blocks:
            for stmt in block.children:
                self.process(stmt, lines, signal_count)

        return lines

    def convert(self, progress_callback=None) -> int:
        """Convert STIL file to GASC format
        
        Args:
            progress_callback: Progress callback function, accepts (current_step, total_steps, message) parameters
        """
        total_steps = 4
        
        if progress_callback:
            progress_callback(1, total_steps, "Starting STIL file parsing...")
        
        # Get file size for estimation
        file_size = os.path.getsize(self.stil_file) if os.path.exists(self.stil_file) else 0
        size_mb = file_size / (1024 * 1024)
        
        if progress_callback:
            progress_callback(1, total_steps, f"File size: {size_mb:.1f}MB, parsing syntax...")
            
        # OPTIMIZATION: Choose parser settings based on fast_mode
        if self.fast_mode:
            # Fast mode: disable position tracking and debug for large files
            parser = STILParser(self.stil_file, propagate_positions=False, debug=False)
        else:
            # Standard mode: keep all features
            parser = STILParser(self.stil_file, propagate_positions=True, debug=False)
            
        tree = parser.parse_syntax(debug=False, preprocess_include=not self.fast_mode)
        
        if progress_callback:
            progress_callback(2, total_steps, "Extracting signal definitions...")
            
        signals = self.extract_signals(tree)
        sig_groups = self.extract_signal_groups(tree)
        
        if progress_callback:
            progress_callback(3, total_steps, f"Extracting pattern data (found {len(signals)} signals)...")
            
        patt_lines = self.extract_pattern_lines(tree, len(signals))
        
        if progress_callback:
            progress_callback(4, total_steps, f"Generating output file (processing {len(patt_lines)} pattern lines)...")
        
        # the V key is unknown, so we need to get the key from signals or sig_groups
        final_signals = []
        for key in self.pat_header:
            if key in sig_groups:
                final_signals.extend(sig_groups[key])
            elif key in signals:
                final_signals.append(signals[key])
        with open(self.target_file, "w", encoding="utf-8") as fh:
            # write signals
            fh.write("Signals {\n")
            fh.write("     " + ",".join(signals) + ";\n\n")
            fh.write("}\n\n")
            # write signal groups
            if sig_groups:
                fh.write("SignalGroups {\n")
                for name, sigs in sig_groups.items():
                    fh.write("     {} = '{}';\n".format(name, " + ".join(sigs)))
                fh.write("}\n\n")
            # write header
            fh.write("HEADER { \n")
            fh.write("     " + ",".join(final_signals) + ";\n")
            fh.write("}\n\n")
            # write pattern
            fh.write("SPM_PATTERN (SCAN) {\n")
            for pl in patt_lines:
                fh.write(f"       *{pl.vec}* {pl.instr};")
                if pl.wft:
                    fh.write(f"{pl.wft};")
                fh.write("\n")
            fh.write("}\n")
        
        if progress_callback:
            progress_callback(4, total_steps, "Conversion completed!")
            
        return 0

if __name__ == "__main__":  # pragma: no cover - simple CLI wrapper
    #stil_to_gasc = STILToGasc("tests/stil_files/pattern_block/syn_ok_pattern_block_2.stil",
    #     "gpt_tests/result1.gasc")
    # stil_to_gasc.convert()
    # stil_to_gasc = STILToGasc("gpt_tests/utc_010_bypass.stil",
    #     "gpt_tests/result2.gasc")
    stil_to_gasc = STILToGasc("C:/Users/admin/Desktop/1/utc_010_bypass.stil",
        "C:/Users/admin/Desktop/1/result.gasc")
    raise SystemExit(stil_to_gasc.convert())