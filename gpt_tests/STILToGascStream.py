"""Utility to convert STIL files to simple GASC format.

This script demonstrates how to use the ``STILParser`` from the project to
parse a STIL file and extract a very small subset of the information.  The
result is written to a ``.gasc`` file with a structure similar to the one
requested in the user instructions.

The script is intentionally lightweight and only relies on the parse tree
structure generated by ``STILParser``.  It walks the tree and collects:

* The signal names declared in the ``Signals`` block.
* The vector data contained in pattern statements.
* Micro-instructions (``Call``, ``Loop``, ``Stop`` …) that immediately
  precede a vector.
* The active waveform table (``W`` statement).

The produced ``.gasc`` file contains a header with the list of signals and a
``SPM_PATTERN (SCAN)`` block with one line per vector.  Each line contains the
vector data, the micro-instruction and the waveform table name, when
available.

Note
----
The repository does not ship the ``lark`` dependency that powers the parser.
Running this script requires installing ``lark`` into the environment.

OPTIMIZED VERSION with streaming output and real-time progress display.
"""

from __future__ import annotations

import os
from queue import Empty
import sys
from dataclasses import dataclass
from typing import List
from TimingData import TimingData
from lark import Lark, Tree, Token, LarkError

try:  # Try importing the package as an installed dependency first
    from Semi_ATE.STIL.parsers.STILParser import STILParser
except ImportError:  # pragma: no cover - fallback for local execution
    repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, repo_root)
    from Semi_ATE.STIL.parsers.STILParser import STILParser

from lark import Tree, Token


@dataclass
class PatternLine:
    """模式行数据结构"""
    vec: str      # 向量数据
    instr: str    # 微指令
    wft: str      # 波形表名称

class STILToGascStream():
    """Convert STIL files to a simple GASC-like format - STREAMING OPTIMIZED VERSION."""

    def __init__(self, stil_file, target_file, progress_callback=None, debug=False):
        """初始化转换器
        
        Args:
            stil_file: 输入STIL文件路径
            target_file: 输出GASC文件路径  
            fast_mode: 是否启用快速模式（大文件优化）
        """
        self.stil_file = stil_file
        self.target_file = target_file
        self.file_size = -1  # 文件大小
        self.read_size = 0  # 已读取字节数
        # Pattern line tracking
        self.current_wft = ""
        self.wft_pending = False
        self.pat_header: List[str] = []
        self.need_append_header = True
        self.label_value = ""

        # Streaming output
        #self.output_file = None
        # Open output file for streaming
        self.output_file = open(target_file, "w", encoding="utf-8")
        self.header_written = False
        self.pattern_section_started = False
        
        # Progress tracking
        self.vector_count = 0
        #self.progress_callback = None
        self.progress_callback = progress_callback

        #debug = False
        self.debug = debug
        grammar_base = os.path.join(os.path.dirname(__file__), "..", "Semi_ATE", "STIL", "parsers", "grammars")
        # 构建完整的语法
        pattern_statements_file = os.path.join(grammar_base, "pattern_statements.lark")
        try:
            # 读取pattern_statements语法（它会自动通过import_paths导入base.lark）
            with open(pattern_statements_file, 'r') as f:
                pattern_grammar = f.read()
            
            # 添加空格和注释忽略规则（让解析器忽略空格和注释）
            ignore_whitespace = """
            %import common.WS
            %ignore WS
            %import common.CPP_COMMENT  
            %ignore CPP_COMMENT
            %import common.NEWLINE
            %ignore NEWLINE
            """
            # 创建能解析多个pattern_statement的语法
            multi_grammar = """
            start: pattern_statement+
            """ + pattern_grammar + ignore_whitespace
            
            self.multi_parser = Lark(
                multi_grammar,
                start="start",
                parser="lalr",
                import_paths=[grammar_base]
            )
            print("Pattern语句解析器初始化成功")
        except Exception as e:
            print(f"Pattern语句解析器初始化失败: {e}")

    def get_multi_parser(self):
        return self.multi_parser
    
    # ========================== get signals and group ==========================
    # get signal name from tree
    def extract_signals(self, tree: Tree) -> List[str]:
        """从Signals块提取信号名称列表"""
        signals: List[str] = []
        
        # Keep original node name that works
        for node in tree.find_data("b_signals__signals_list"):
            token = node.children[0]
            if isinstance(token, Token):
                signals.append(token.value.strip("\""))
        return signals
    
    # get signal group name from tree
    def extract_signal_groups(self, tree: Tree) -> dict[str, List[str]]:
        """从SignalGroups块提取信号组映射关系"""
        groups: dict[str, List[str]] = {}
        
        for node in tree.find_data("signal_groups_block"):
            # get second elemet in children of signal_groups_block and get value
            if (isinstance(node.children[1], Token)):
                name_ref = node.children[1].value
                print(name_ref)
            else:
                name_ref = ""
            # Keep original node name that works
            for node in node.find_data("b_signal_groups__signal_groups_list"):
                tokens = [c for c in node.children if isinstance(c, Token)]
                if len(tokens) < 2:
                    continue
                name = tokens[0].value
                sigs: List[str] = [tokens[1].value.strip("\"")]
                
                for vb in node.find_data("b_signal_groups__sigref_expr"):
                    # for nin vb.children, if n.type is b_signal_groups__SIGREF_NAME, then add n.value to sigs
                    for n in vb.children:
                        if isinstance(n, Token) and n.type == "b_signal_groups__SIGREF_NAME":
                            sigs.append(n.value.strip("\""))
                if name_ref != "":
                    groups[name_ref + "." + name] = sigs
                else:
                    groups[name] = sigs
        return groups

    # ========================== get timings ==========================
    # get timing from tree
    def write_timing(self, tree: Tree) -> {str, List[TimingData]}:
        """从Timing块提取Timing信息"""
        # construct TimingData
        for node in tree.find_data("timing_block"):
            timings = {};
            timing_data_list = []
            # the timing_block contains b_timing__waveform_table
            for node in node.find_data("b_timing__waveform_table"):
                wft = "";
                period = "";
                for child in node.children:
                    # get b_timing__WFT_NAME from b_timing__waveform_table
                    if isinstance(child, Token) and child.type == "b_timing__WFT_NAME":
                        wft = child.value
                    # get 'b_timing__period' from b_timing__waveform_table
                    if (isinstance(child, Tree)
                     and child.data == "b_timing__period"
                     and len(child.children) == 2):
                        if isinstance(child.children[1], Token):
                            period = child.children[1].value.replace("'", "");
                timings.setdefault(wft, [])
                # get 'b_timing__waveforms_list' from b_timing__waveform_table
                for child in node.find_data("b_timing__waveforms_list"):
                    time_values = []
                    edge_values = []
                    timing_data = TimingData()
                    timing_data.wft = wft
                    timing_data.period = period
                    for subchild in child.children:
                        # get signal form 'b_timing__WF_SIGREF_EXPR' in Token
                        if isinstance(subchild, Token) and subchild.type == "b_timing__WF_SIGREF_EXPR":
                            timing_data.signal = subchild.value
                        # if subchild is Token and subchild.type is 'b_timing__WFC_LIST', then get value
                        if isinstance(subchild, Token) and subchild.type == "b_timing__WFC_LIST":
                            timing_data.wfc = subchild.value
                        if (isinstance(subchild, Tree)
                         and subchild.data == "b_timing__time_offset"
                         and len(subchild.children) == 2):
                            self._process_single_time_offset(subchild, timing_data, time_values, edge_values)
                        if (isinstance(subchild, Tree) and subchild.data == "b_timing__close_wfcs_block"):
                            # 将提取的数据分配到TimingData的相应字段
                            self._assign_timing_data(timing_data, time_values, edge_values)
                            # ==================== TimingData 拆分逻辑 ====================
                            timing_list = self._split_timing_data(timing_data)
                            timings[wft].extend(timing_list)
                            time_values.clear()
                            edge_values.clear()
                            timing_data = TimingData()
                            timing_data.wft = wft
                            timing_data.period = period
        return timings

    def _split_timing_data(self, timing_data: TimingData) -> None:
        timing_data_list = []
        if len(timing_data.wfc) > 1:
            # 获取timing_data.edge1中是否存在和timing_data.wfc字符个数相同的字符串
            edge1 = ""
            if len(timing_data.e1) == len(timing_data.wfc):
                edge1 = timing_data.e1
            else:
                edge1 = timing_data.e1 * len(timing_data.wfc)
            if (edge1.strip() != ""):
                # 创建TimingData，把timing_data.edge1拆分多个TimingData，并添加到timing_data_list
                for i in range(len(edge1)):
                    timing_data_child = TimingData()
                    timing_data_child.wft = timing_data.wft
                    timing_data_child.period = timing_data.period
                    timing_data_child.signal = timing_data.signal
                    timing_data_child.wfc = timing_data.wfc[i:i+1]
                    timing_data_child.t1 = timing_data.t1
                    timing_data_child.e1 = timing_data.e1[i:i+1]
                    timing_data_list.append(timing_data_child)
                    timing_data.twas.append(timing_data_child)
            edge2 = ""
            if len(timing_data.e2) == len(timing_data.wfc):
                edge2 = timing_data.e2
            else:
                edge2 = timing_data.e2 * len(timing_data.wfc)
            if (edge2.strip() != ""):
                # 如果timing_data.edge2也存在多个字符，判断是否和timing_wfc字符数相同, 如果相同添加到timing_data_List中的TimingData中
                for i in range(len(edge2)):
                    timing_data_child = timing_data_list[i]
                    timing_data_child.wft = timing_data.wft
                    timing_data_child.period = timing_data.period
                    timing_data_child.signal = timing_data.signal
                    timing_data_child.wfc = timing_data.wfc[i:i+1]
                    timing_data_child.time2 = timing_data.t2
                    timing_data_child.edge2 = timing_data.e2[i:i+1]
            edge3 = ""
            if len(timing_data.e3) == len(timing_data.wfc):
                edge3 = timing_data.e3
            else:
                edge3 = timing_data.e3 * len(timing_data.wfc)
            if (edge3.strip() != ""):
                # 如果timing_data.edge3也存在多个字符，判断是否和timing_wfc字符数相同，如果相同添加到timing_data_List中的TimingData中
                for i in range(len(edge3)):
                    timing_data_child = timing_data_list[i]
                    timing_data_child.wft = timing_data.wft
                    timing_data_child.period = timing_data.period
                    timing_data_child.signal = timing_data.signal
                    timing_data_child.wfc = timing_data.wfc[i:i+1]
                    timing_data_child.time3 = timing_data.t3
                    timing_data_child.edge3 = timing_data.e3[i:i+1]
            edge4 = ""
            if len(timing_data.e4) == len(timing_data.wfc):
                edge4 = timing_data.e4
            else:
                edge4 = timing_data.e4 * len(timing_data.wfc)
            if (edge4.strip() != ""):
                # 如果timing_data.edge4也存在多个字符，判断是否和timing_wfc字符数相同，如果相同添加到timing_data_List中的TimingData中
                for i in range(len(edge4)):
                    timing_data_child = timing_data_list[i]
                    timing_data_child.wft = timing_data.wft
                    timing_data_child.period = timing_data.period
                    timing_data_child.signal = timing_data.signal
                    timing_data_child.wfc = timing_data.wfc[i:i+1]
                    timing_data_child.time4 = timing_data.t4
                    timing_data_child.edge4 = timing_data.e4[i:i+1]
        else:
            timing_data_list.append(timing_data)
        return timing_data_list

    def _process_single_time_offset(self, time_offset_node: Tree,
             timing_data: TimingData, time_values: List, edge_values: List) -> None:
        """处理单个time_offset节点，提取所有time/edge对"""
        for child in time_offset_node.children:
            if isinstance(child, Token) and child.type == "b_timing__TIME_EXPR":
                # 检查是否是时间表达式
                time_values.append(child.value)
            # if child is Token and child.typ=='b_timing__EVENT' 
            if isinstance(child, Token) and child.type == "b_timing__EVENT":
            # 检查是否是事件/边沿
                edge_values.append(child.value)
            # if child is Tree and child.data == "b_timing__events"
            if isinstance(child, Tree) and child.data == "b_timing__events":
                edges = "";
                for subchild in child.children:
                    if isinstance(subchild, Token) and subchild.type == "b_timing__EVENT":
                        edges += subchild.value
                edge_values.append(edges)
                    

    def _is_timing_event(self, value: str) -> bool:
        """检查给定值是否为有效的时序事件"""
        timing_events = {
            'D', 'U', 'P', 'Z',  # Force events
            'L', 'H', 'X', 'x', 'T', 'V',  # Compare events
            'l', 'h', 't', 'v',  # Window events
            'ForceDown', 'ForceUp', 'ForcePrior', 'ForceOff',
            'CompareLow', 'CompareHigh', 'CompareUnknown', 'CompareOff',
            'CompareValid', 'CompareLowWindow', 'CompareHighWindow',
            'CompareOffWindow', 'CompareValidWindow'
        }
        return value in timing_events

    def _assign_timing_data(self, timing_data: TimingData, times: List[str], edges: List[str]) -> None:
        """将时间和边沿数据分配到TimingData对象的相应字段"""
        # 处理时间/边沿对，最多支持4对
        max_pairs = min(4, len(times), len(edges))
        
        for i in range(max_pairs):
            time_attr = f"t{i+1}"
            edge_attr = f"e{i+1}"
            
            if hasattr(timing_data, time_attr) and hasattr(timing_data, edge_attr):
                setattr(timing_data, time_attr, times[i].replace("'", ""))
                setattr(timing_data, edge_attr, edges[i])

    # ========================== get vec data ==========================
    def expand_vec_data(self, data: str) -> str:
        """展开向量数据中的重复指令，如 \\r98 X
        
        支持的格式：
        1. \\r98 X -> XXXXXXX...
        2. XLLL \\r98 X HHH \\r4 H LL -> XLLLXXXXXXX...HHHHHHHLL
        """
        import re
        
        # 使用正则表达式匹配 \r数字 后跟一个或多个字符的模式
        # 模式: \r后跟数字，然后是空格，然后是要重复的内容
        pattern = r'\\r(\d+)\s+([^\s\\]+)'
        
        def replace_repeat(match):
            repeat_count = int(match.group(1))
            repeat_content = match.group(2)
            return repeat_content * repeat_count
        
        # 反复应用替换，直到没有更多的重复指令
        result = data
        while '\\r' in result:
            new_result = re.sub(pattern, replace_repeat, result)
            if new_result == result:  # 没有更多替换，避免无限循环
                break
            result = new_result
        
        # 去除多余的空格
        result = re.sub(r'\s+', '', result)
        
        return result

    def write_pattern_line_streaming(self, vec: str, instr: str, wft: str, label_value: str) -> None:
        """流式写入模式行数据到输出文件"""
        if not self.pattern_section_started:
            self.output_file.write("SPM_PATTERN (SCAN) {\n")
            self.pattern_section_started = True
        line = f"       *{vec}*"
        if instr:
            line += f"#{instr}"
        if wft:
            line += f";{wft}"
        if label_value:
            line += f"{label_value.strip(":").strip("\"")}"
        self.output_file.write(line + "\n")

    def emit_streaming(self, vec: str, micro_tokens: List[str], current_wft: str, wft_pending: bool, label_value: str) -> None:
        """输出单个模式行（流式处理）"""
        wft = current_wft if wft_pending else ""
        if wft_pending:
            self.wft_pending = False
        instr = " ".join(micro_tokens)
        if instr == "V":
            instr = ""
        # if len(micro_tokens) == 2 and micro_tokens[0] == "Loop":
        #     # 如果 micro_tokens[1] 是数字并且大于0，则根据 micro_tokens[1]循环
        #     count = micro_tokens[1]
        #     if count.isdigit() and int(count) > 0:
        #         self.progress_callback(f"解析Loop {count}")
        #         for i in range(int(count)):
        #             self.write_pattern_line_streaming(vec, "", wft, label_value)
        #             if i % 5000 == 0:
        #                 self.progress_callback(f"已处理 {i} / {count} 个向量")
        #         self.vector_count += int(count)
        #         self.progress_callback(f"已处理 {self.vector_count:,} 个向量")
        # else:
        self.write_pattern_line_streaming(vec, instr, wft, label_value)
        # Update progress counter
        self.vector_count += 1
        # 优化进度更新频率：前10000个每1000更新，之后每5000更新
        update_interval = 1000 if self.vector_count <= 10000 else 5000
        if self.progress_callback and self.vector_count % update_interval == 0:
            progress = self.read_size / self.file_size * 100
            self.progress_callback(f"已处理 {self.vector_count:,} 个向量，进度:{progress:.1f}%...")

    # get Tree under b_pattern__pattern_statements_
    def process_streaming(self, node: Tree, micro_tokens: List[str], signal_count: int) -> None:
        """递归处理模式语句节点（流式输出）"""
        # if node is Token and node.type is LABEL, record node.value to next pattern_statement
        if isinstance(node, Token) and node.type == "LABEL":
            self.label_value = node.value
            return
        if not isinstance(node, Tree):
            return
        data = node.data
        if data.endswith("pattern_statement"):
            for child in node.children:
                self.process_streaming(child, micro_tokens, signal_count)
            return
        # skip annotation, open_pattern_block, close_pattern_block
        if (data.endswith("annotation")
         or data.endswith("open_pattern_block")
         or data.endswith("close_pattern_block")):
            return
        # get waveform table name from w_stmt
        if data.endswith("w_stmt"):
            tokens = [t.value for t in node.children if isinstance(t, Token)]
            if len(tokens) >= 2:
                self.current_wft = tokens[1]
                self.wft_pending = True
            return
        # get micro-instruction from pattern_statement
        micro_tokens_temp = [c.value for c in node.children if isinstance(c, Token)][:2]
        mirco = " ".join(micro_tokens_temp)
        if (mirco != "V"):
            micro_tokens = micro_tokens_temp
        # get vec_block Tree under b_pattern__pattern_statements_
        has_vec = any(isinstance(ch, Tree) and ch.data.endswith("vec_block") for ch in node.children)
        # get pattern_statement Tree under b_pattern__pattern_statements_
        nested = [ch for ch in node.children if isinstance(ch, Tree) and ch.data.endswith("pattern_statement")]
        # get vec_data_block Tree under b_pattern__pattern_statements_
        if has_vec:
            vec_parts: List[str] = []
            for vb in node.iter_subtrees():
                if isinstance(vb, Tree) and vb.data.endswith("vec_data_block"):
                    vec_tokens = [t.value for t in vb.scan_values(lambda c: isinstance(c, Token))]
                    if vec_tokens:
                        # record header when read first V list
                        if self.need_append_header:
                            self.pat_header.append(vec_tokens[0].strip())
                        vec_parts.append(self.expand_vec_data(vec_tokens[-1].strip()))
            vec = "".join(vec_parts)
            # if vec length < signal_count, then add X to vec_parts
            if len(vec) < signal_count:
                vec += "X" * (signal_count - len(vec))
            # create method to transform vec char to other char
            vec = self.transform_vec_char(vec)
            self.need_append_header = False
            self.emit_streaming(vec, micro_tokens, self.current_wft, self.wft_pending, self.label_value)
            # label_value only used for one pattern_statement
            self.label_value = ""
            return
        if nested:
            for child in nested:
                self.process_streaming(child, micro_tokens, signal_count)
            return

        vec = "X" * signal_count
        self.emit_streaming(vec, micro_tokens, self.current_wft, self.wft_pending)

    # ========================== main convert method ==========================
    def convert(self) -> int:
        """主转换函数：将STIL文件转换为GASC格式（流式输出）
        
        Args:
            progress_callback: 进度回调函数，接收消息参数
        """
        self.vector_count = 0
        
        if self.progress_callback:
            self.progress_callback("开始解析STIL文件...")
        
        # Get file size for estimation
        self.file_size = os.path.getsize(self.stil_file) if os.path.exists(self.stil_file) else 0
        size_mb = self.file_size / (1024 * 1024)
        self.read_size = 0  # 已读取字节数
        
        if self.progress_callback:
            self.progress_callback(f"文件大小: {size_mb:.1f}MB，开始语法解析...")

        header_buffer = "";
        buffer_lines = []
        isPattern = False
        signalCount = 0
        if self.progress_callback:
            self.progress_callback(f"打开文件，{self.stil_file}")
        with open(self.stil_file, 'r', encoding='utf-8') as f:
            #read every line in the file
            if self.progress_callback:
                self.progress_callback("开始提取信号/组/Timing内容...")
            for line in f:
                self.read_size += len(line)
                if (line.strip().startswith('Pattern ') and '{' in line):
                    isPattern = True;
                    if self.debug:
                        print(header_buffer)
                    if self.progress_callback:
                        self.progress_callback("开始信号/组/Timing语法解析...")
                    parser = STILParser(self.stil_file, propagate_positions=True, debug=self.debug)
                    tree = parser.parse_content(header_buffer)
                    if self.debug:
                        print(tree.pretty())
                    if self.progress_callback:
                        self.progress_callback("信号/组/Timing语法解析完成...")
                        self.progress_callback("开始转换信号/组定义...")
                    signals = self.extract_signals(tree)
                    sig_groups = self.extract_signal_groups(tree)
                    signalCount = len(signals)
                    if self.progress_callback:
                        self.progress_callback(f"找到 {signalCount} 个信号...")
                   
                    # Write signals
                    self.output_file.write("Signals {\n")
                    self.output_file.write("     " + ",".join(signals) + ";\n\n")
                    self.output_file.write("}\n\n")
                    
                    # Write signal groups
                    if sig_groups:
                        self.output_file.write("SignalGroups {\n")
                        for name, sigs in sig_groups.items():
                            self.output_file.write("     {} = '{}';\n".format(name, " + ".join(sigs)))
                        self.output_file.write("}\n\n")
                        
                    # Write timing to single file
                    self.output_file.write("Timing {\n")
                    timings = self.write_timing(tree)
                    # write timings to file
                    for key, timing in timings.items():
                        for timing_data in timing:
                            self.output_file.write(f"     {timing_data.wft}, {timing_data.period}, ")
                            self.output_file.write(f"{timing_data.signal}, {timing_data.wfc}, ")
                            self.output_file.write(f"{timing_data.t1}, {timing_data.e1}, ")
                            self.output_file.write(f"{timing_data.t2}, {timing_data.e2}, ")
                            self.output_file.write(f"{timing_data.t3}, {timing_data.e3}, ")
                            self.output_file.write(f"{timing_data.t4}, {timing_data.e4};\n")
                    self.output_file.write("}\n\n")

                    if self.progress_callback:
                        self.progress_callback("信号/组/Timing转换完成...")
                    break
                if not isPattern:
                    header_buffer += line
                    continue

            if self.progress_callback:
                self.progress_callback("开始转换Pattern内容...")
            for line in f:
                self.read_size += len(line)
                statement_buffer = "".join(buffer_lines).strip()
                try:
                    # 如果包含'{'和'}'，并且数量相同就进入解析
                    if ('{' in statement_buffer and '}' in statement_buffer
                        and (statement_buffer.count('{') == statement_buffer.count('}'))):
                        tree = self.multi_parser.parse(statement_buffer)
                        self.process_streaming(tree, [], signalCount)
                        buffer_lines.clear()
                        buffer_lines.append(line)
                        if self.debug:
                            print(f"解析成功: {statement_buffer}")
                            self.flush()
                        continue
                    # else append line to buffer_lines
                    buffer_lines.append(line)
                except LarkError: 
                    buffer_lines.append(line)
                    if self.debug:
                        print(f"解析失败: {line}")
                except Exception as e:
                    buffer_lines.append(line)
                    if self.debug:
                        print(f"其他错误: {e}")
            if self.progress_callback:
                self.progress_callback(f"已处理 {self.vector_count:,} 个向量，进度:{100:.1f}%...")
        self.close()
        self.finalize_header(signals, sig_groups)
        if self.progress_callback:
            self.progress_callback(f"转换完成！总共处理了 {self.vector_count} 个向量")
            
        return 0

    def transform_vec_char(self, vec: str) -> str:
        """将vec中的字符转换为其他字符"""
        """
            wt1, 40ns, input_time_gen_0, 0, 0ns, D, , , , , , ;
            wt1, 40ns, input_time_gen_0, 1, 0ns, U, , , , , , ;
            wt1, 40ns, input_time_gen_0, N, 0ns, N, , , , , , ;
            wt1, 40ns, _po_, L, 10ns, l, , , , , , ;
            wt1, 40ns, _po_, H, 10ns, h, , , , , , ;
            wt1, 40ns, _po_, X, 10ns, X, , , , , , ;
            wt1, 40ns, _po_, T, 10ns, t, , , , , , ;
            wt1, 40ns, _po_, Z, 10ns, Z, , , , , , ;
            wt1, 40ns, _bidi_, 0, 0ns, Z, , , , , , ;
            wt1, 40ns, _bidi_, 1, 0ns, , , , , , , ;
            wt1, 40ns, _bidi_, Z, 0ns, , , , , , , ;
            wt1, 40ns, _bidi_, N, 0ns, , , , , , , ;
        """
        return vec

    def finalize_header(self, signals: List[str], sig_groups: dict[str, List[str]]) -> None:
        """完善文件头部，确定最终的模式信号列表"""
        # 使用第一条Vector的信号/信号组名，先从sig_groups中获取，获取不到则从signals中获取
        # Determine final signals based on pattern header
        final_signals = []
        for key in self.pat_header:
            if key in sig_groups:
                final_signals.extend(sig_groups[key])
            elif key in signals:
                final_signals.append(key)
        # We need to close current file and rewrite with proper header
        if self.output_file:
            temp_file = self.target_file + ".tmp"
            # Write complete header to temp file
            with open(temp_file, "w", encoding="utf-8") as temp_fh:
                # Write proper header
                temp_fh.write("HEADER { \n")
                temp_fh.write("     " + ",".join(final_signals) + ";\n")
                temp_fh.write("}\n\n")
                # Copy pattern section from original file
                self.output_file.close()
                with open(self.target_file, "r", encoding="utf-8") as orig_fh:
                    content = orig_fh.read()
                temp_fh.write(content)
                temp_fh.write("}\n")
            # Replace original with temp file
            import shutil
            shutil.move(temp_file, self.target_file)

    def close(self):
        if self.output_file and not self.output_file.closed:
            self.output_file.close()

    def flush(self):
        if self.output_file and not self.output_file.closed:
            self.output_file.flush()