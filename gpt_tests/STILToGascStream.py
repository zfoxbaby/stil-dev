"""Utility to convert STIL files to simple GASC format.

This script demonstrates how to use the ``STILParser`` from the project to
parse a STIL file and extract a very small subset of the information.  The
result is written to a ``.gasc`` file with a structure similar to the one
requested in the user instructions.

The script is intentionally lightweight and only relies on the parse tree
structure generated by ``STILParser``.  It walks the tree and collects:

* The signal names declared in the ``Signals`` block.
* The vector data contained in pattern statements.
* Micro-instructions (``Call``, ``Loop``, ``Stop`` …) that immediately
  precede a vector.
* The active waveform table (``W`` statement).

The produced ``.gasc`` file contains a header with the list of signals and a
``SPM_PATTERN (SCAN)`` block with one line per vector.  Each line contains the
vector data, the micro-instruction and the waveform table name, when
available.

Note
----
The repository does not ship the ``lark`` dependency that powers the parser.
Running this script requires installing ``lark`` into the environment.

OPTIMIZED VERSION with streaming output and real-time progress display.
"""

from __future__ import annotations

import os
from queue import Empty
import sys
from dataclasses import dataclass
from typing import List

from lark import Lark, Tree, Token, LarkError

try:  # Try importing the package as an installed dependency first
    from Semi_ATE.STIL.parsers.STILParser import STILParser
except ImportError:  # pragma: no cover - fallback for local execution
    repo_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, repo_root)
    from Semi_ATE.STIL.parsers.STILParser import STILParser

from lark import Tree, Token


@dataclass
class PatternLine:
    """模式行数据结构"""
    vec: str      # 向量数据
    instr: str    # 微指令
    wft: str      # 波形表名称

class STILToGascStream():
    """Convert STIL files to a simple GASC-like format - STREAMING OPTIMIZED VERSION."""

    def __init__(self, stil_file, target_file, progress_callback=None, debug=False):
        """初始化转换器
        
        Args:
            stil_file: 输入STIL文件路径
            target_file: 输出GASC文件路径  
            fast_mode: 是否启用快速模式（大文件优化）
        """
        self.stil_file = stil_file
        self.target_file = target_file
        self.file_size = -1  # 文件大小
        self.read_size = 0  # 已读取字节数
        # Pattern line tracking
        self.current_wft = ""
        self.wft_pending = False
        self.pat_header: List[str] = []
        self.need_append_header = True
        self.label_value = ""

        # Streaming output
        #self.output_file = None
        # Open output file for streaming
        self.output_file = open(target_file, "w", encoding="utf-8")
        self.header_written = False
        self.pattern_section_started = False
        
        # Progress tracking
        self.vector_count = 0
        #self.progress_callback = None
        self.progress_callback = progress_callback

        #debug = False
        self.debug = debug
        grammar_base = os.path.join(os.path.dirname(__file__), "..", "Semi_ATE", "STIL", "parsers", "grammars")
        # 构建完整的语法
        pattern_statements_file = os.path.join(grammar_base, "pattern_statements.lark")
        try:
            # 读取pattern_statements语法（它会自动通过import_paths导入base.lark）
            with open(pattern_statements_file, 'r') as f:
                pattern_grammar = f.read()
            
            # 添加空格和注释忽略规则（让解析器忽略空格和注释）
            ignore_whitespace = """
            %import common.WS
            %ignore WS
            %import common.CPP_COMMENT  
            %ignore CPP_COMMENT
            %import common.NEWLINE
            %ignore NEWLINE
            """
            # 创建能解析多个pattern_statement的语法
            multi_grammar = """
            start: pattern_statement+
            """ + pattern_grammar + ignore_whitespace
            
            self.multi_parser = Lark(
                multi_grammar,
                start="start",
                parser="lalr",
                import_paths=[grammar_base]
            )
            print("Pattern语句解析器初始化成功")
        except Exception as e:
            print(f"Pattern语句解析器初始化失败: {e}")

    def get_multi_parser(self):
        return self.multi_parser
    
    # ========================== get signals and group ==========================
    # get signal name from tree
    def extract_signals(self, tree: Tree) -> List[str]:
        """从Signals块提取信号名称列表"""
        signals: List[str] = []
        
        # Keep original node name that works
        for node in tree.find_data("b_signals__signals_list"):
            token = node.children[0]
            if isinstance(token, Token):
                signals.append(token.value.strip("\""))
        return signals
    
    # get signal group name from tree
    def extract_signal_groups(self, tree: Tree) -> dict[str, List[str]]:
        """从SignalGroups块提取信号组映射关系"""
        groups: dict[str, List[str]] = {}
        
        for node in tree.find_data("signal_groups_block"):
            # get second elemet in children of signal_groups_block and get value
            if (isinstance(node.children[1], Token)):
                name_ref = node.children[1].value
                print(name_ref)
            else:
                name_ref = ""
            # Keep original node name that works
            for node in node.find_data("b_signal_groups__signal_groups_list"):
                tokens = [c for c in node.children if isinstance(c, Token)]
                if len(tokens) < 2:
                    continue
                name = tokens[0].value
                sigs: List[str] = [tokens[1].value.strip("\"")]
                
                for vb in node.find_data("b_signal_groups__sigref_expr"):
                    # for nin vb.children, if n.type is b_signal_groups__SIGREF_NAME, then add n.value to sigs
                    for n in vb.children:
                        if isinstance(n, Token) and n.type == "b_signal_groups__SIGREF_NAME":
                            sigs.append(n.value.strip("\""))
                if name_ref != "":
                    groups[name_ref + "." + name] = sigs
                else:
                    groups[name] = sigs
        return groups

    # ========================== get timings ==========================
    # get timing from tree
    def write_timing(self, tree: Tree) -> None:
        """从Timing块提取Timing信息"""
        for node in tree.find_data("timing_block"):
            print(node)

    # ========================== get vec data ==========================
    def expand_vec_data(self, data: str) -> str:
        """展开向量数据中的重复指令，如 \\r98 X
        
        支持的格式：
        1. \\r98 X -> XXXXXXX...
        2. XLLL \\r98 X HHH \\r4 H LL -> XLLLXXXXXXX...HHHHHHHLL
        """
        import re
        
        # 使用正则表达式匹配 \r数字 后跟一个或多个字符的模式
        # 模式: \r后跟数字，然后是空格，然后是要重复的内容
        pattern = r'\\r(\d+)\s+([^\s\\]+)'
        
        def replace_repeat(match):
            repeat_count = int(match.group(1))
            repeat_content = match.group(2)
            return repeat_content * repeat_count
        
        # 反复应用替换，直到没有更多的重复指令
        result = data
        while '\\r' in result:
            new_result = re.sub(pattern, replace_repeat, result)
            if new_result == result:  # 没有更多替换，避免无限循环
                break
            result = new_result
        
        # 去除多余的空格
        result = re.sub(r'\s+', '', result)
        
        return result

    def write_pattern_line_streaming(self, vec: str, instr: str, wft: str, label_value: str) -> None:
        """流式写入模式行数据到输出文件"""
        if not self.pattern_section_started:
            self.output_file.write("SPM_PATTERN (SCAN) {\n")
            self.pattern_section_started = True

        self.output_file.write(f"       *{vec}*{instr};")
        if wft:
            self.output_file.write(f"{wft};")
        if label_value: # strip ':' and '"'
            self.output_file.write(f"{label_value.strip(":").strip("\"")};")
        self.output_file.write("\n")
        
        # Update progress counter
        self.vector_count += 1
        # 优化进度更新频率：前10000个每1000更新，之后每5000更新
        update_interval = 1000 if self.vector_count <= 10000 else 5000
        if self.progress_callback and self.vector_count % update_interval == 0:
            progress = self.read_size / self.file_size * 100
            self.progress_callback(f"已处理 {self.vector_count:,} 个向量，进度:{progress:.1f}%...")

    def emit_streaming(self, vec: str, instr: str, current_wft: str, wft_pending: bool, label_value: str) -> None:
        """输出单个模式行（流式处理）"""
        wft = current_wft if wft_pending else ""
        if wft_pending:
            self.wft_pending = False
        self.write_pattern_line_streaming(vec, instr, wft, label_value)

    # get Tree under b_pattern__pattern_statements_
    def process_streaming(self, node: Tree, signal_count: int) -> None:
        """递归处理模式语句节点（流式输出）"""
        # if node is Token and node.type is LABEL, record node.value to next pattern_statement
        if isinstance(node, Token) and node.type == "LABEL":
            self.label_value = node.value
            return
        if not isinstance(node, Tree):
            return
        data = node.data
        if data.endswith("pattern_statement"):
            for child in node.children:
                self.process_streaming(child, signal_count)
            return
        # skip annotation, open_pattern_block, close_pattern_block
        if (data.endswith("annotation")
         or data.endswith("open_pattern_block")
         or data.endswith("close_pattern_block")):
            return
        # get waveform table name from w_stmt
        if data.endswith("w_stmt"):
            tokens = [t.value for t in node.children if isinstance(t, Token)]
            if len(tokens) >= 2:
                self.current_wft = tokens[1]
                self.wft_pending = True
            return
        # get micro-instruction from pattern_statement
        micro_tokens = [c.value for c in node.children if isinstance(c, Token)][:2]
        micro = " ".join(micro_tokens)
        if micro == "V":
            micro = ""
        # get vec_block Tree under b_pattern__pattern_statements_
        has_vec = any(isinstance(ch, Tree) and ch.data.endswith("vec_block") for ch in node.children)
        # get pattern_statement Tree under b_pattern__pattern_statements_
        nested = [ch for ch in node.children if isinstance(ch, Tree) and ch.data.endswith("pattern_statement")]
        # get vec_data_block Tree under b_pattern__pattern_statements_
        if has_vec:
            vec_parts: List[str] = []
            for vb in node.iter_subtrees():
                if isinstance(vb, Tree) and vb.data.endswith("vec_data_block"):
                    vec_tokens = [t.value for t in vb.scan_values(lambda c: isinstance(c, Token))]
                    if vec_tokens:
                        # record header when read first V list
                        if self.need_append_header:
                            self.pat_header.append(vec_tokens[0].strip())
                        vec_parts.append(self.expand_vec_data(vec_tokens[-1].strip()))
            vec = "".join(vec_parts)
            self.need_append_header = False
            self.emit_streaming(vec, micro, self.current_wft, self.wft_pending, self.label_value)
            # label_value only used for one pattern_statement
            self.label_value = ""
            return
        if nested:
            for child in nested:
                self.process_streaming(child, signal_count)
            return

        vec = "X" * signal_count
        self.emit_streaming(vec, micro, self.current_wft, self.wft_pending)

    # ========================== main convert method ==========================
    def convert(self) -> int:
        """主转换函数：将STIL文件转换为GASC格式（流式输出）
        
        Args:
            progress_callback: 进度回调函数，接收消息参数
        """
        self.vector_count = 0
        
        if self.progress_callback:
            self.progress_callback("开始解析STIL文件...")
        
        # Get file size for estimation
        self.file_size = os.path.getsize(self.stil_file) if os.path.exists(self.stil_file) else 0
        size_mb = self.file_size / (1024 * 1024)
        self.read_size = 0  # 已读取字节数
        
        if self.progress_callback:
            self.progress_callback(f"文件大小: {size_mb:.1f}MB，开始语法解析...")

        header_buffer = "";
        buffer_lines = []
        isPattern = False
        signalCount = 0
        if self.progress_callback:
            self.progress_callback(f"打开文件，{self.stil_file}")
        with open(self.stil_file, 'r', encoding='utf-8') as f:
            #read every line in the file
            if self.progress_callback:
                self.progress_callback("开始提取信号/组/Timing内容...")
            for line in f:
                self.read_size += len(line)
                if (line.strip().startswith('Pattern ') and '{' in line):
                    isPattern = True;
                    if self.debug:
                        print(header_buffer)
                    if self.progress_callback:
                        self.progress_callback("开始信号/组/Timing语法解析...")
                    parser = STILParser(self.stil_file, propagate_positions=True, debug=self.debug)
                    tree = parser.parse_content(header_buffer)
                    if self.debug:
                        print(tree.pretty())
                    if self.progress_callback:
                        self.progress_callback("信号/组/Timing语法解析完成...")
                        self.progress_callback("开始转换信号/组定义...")
                    signals = self.extract_signals(tree)
                    sig_groups = self.extract_signal_groups(tree)
                    signalCount = len(signals)
                    if self.progress_callback:
                        self.progress_callback(f"找到 {signalCount} 个信号...")
                   
                    # Write signals
                    self.output_file.write("Signals {\n")
                    self.output_file.write("     " + ",".join(signals) + ";\n\n")
                    self.output_file.write("}\n\n")
                    
                    # Write signal groups
                    if sig_groups:
                        self.output_file.write("SignalGroups {\n")
                        for name, sigs in sig_groups.items():
                            self.output_file.write("     {} = '{}';\n".format(name, " + ".join(sigs)))
                        self.output_file.write("}\n\n")
                        
                    # Write timing to single file
                    self.write_timing(tree)

                    if self.progress_callback:
                        self.progress_callback("信号/组/Timing转换完成...")
                    break
                if not isPattern:
                    header_buffer += line
                    continue

            if self.progress_callback:
                self.progress_callback("开始转换Pattern内容...")
            for line in f:
                self.read_size += len(line)
                statement_buffer = "".join(buffer_lines).strip()
                try:
                    if ('{' not in statement_buffer and (statement_buffer.endswith(';'))
                        or statement_buffer.endswith('}')):
                        tree = self.multi_parser.parse(statement_buffer)
                        self.process_streaming(tree, signalCount)
                        buffer_lines.clear()
                        buffer_lines.append(line)
                        if self.debug:
                            print(f"解析成功: {statement_buffer}")
                            self.flush()

                        continue
                    # else append line to buffer_lines
                    buffer_lines.append(line)
                except LarkError: 
                    buffer_lines.append(line)
                    if self.debug:
                        print(f"解析失败: {line}")
                except Exception as e:
                    buffer_lines.append(line)
                    if self.debug:
                        print(f"其他错误: {e}")
            if self.progress_callback:
                self.progress_callback(f"已处理 {self.vector_count:,} 个向量，进度:{100:.1f}%...")
        self.close()
        self.finalize_header(signals, sig_groups)
        if self.progress_callback:
            self.progress_callback(f"转换完成！总共处理了 {self.vector_count} 个向量")
            
        return 0

    def finalize_header(self, signals: List[str], sig_groups: dict[str, List[str]]) -> None:
        """完善文件头部，确定最终的模式信号列表"""
        # Determine final signals based on pattern header
        final_signals = []
        for key in self.pat_header:
            if key in sig_groups:
                final_signals.extend(sig_groups[key])
            elif key in signals:
                final_signals.append(key)
        # We need to close current file and rewrite with proper header
        if self.output_file:
            temp_file = self.target_file + ".tmp"
            # Write complete header to temp file
            with open(temp_file, "w", encoding="utf-8") as temp_fh:
                # Write proper header
                temp_fh.write("HEADER { \n")
                temp_fh.write("     " + ",".join(final_signals) + ";\n")
                temp_fh.write("}\n\n")
                # Copy pattern section from original file
                self.output_file.close()
                with open(self.target_file, "r", encoding="utf-8") as orig_fh:
                    content = orig_fh.read()
                temp_fh.write(content)
                temp_fh.write("}\n")
            # Replace original with temp file
            import shutil
            shutil.move(temp_file, self.target_file)

    def close(self):
        if self.output_file and not self.output_file.closed:
            self.output_file.close()

    def flush(self):
        if self.output_file and not self.output_file.closed:
            self.output_file.flush()